{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9Tdvwsey8ki/EF6WKeyeN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fopamesmin/4MAc/blob/main/_league1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn9jBkPYvFGA",
        "outputId": "898efa23-c70d-4dea-8660-8bdb257b0011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Données enregistrées dans Google Drive à l'emplacement: /content/drive/My Drive/ligue1_data.csv\n"
          ]
        }
      ],
      "source": [
        "import requests as req\n",
        "from bs4 import BeautifulSoup as BS\n",
        "import logging\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Constantes\n",
        "sofifa_url = \"https://www.ligue1.com/ranking\"\n",
        "COLUMNS = [\"position\", \"team\", \"points\", \"played\", \"won\", \"drawn\", \"lost\", \"gf\", \"ga\"]\n",
        "ID_seasonId = [\"2020/2021\", \"2021/2022\", \"2022/2023\"]\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "def fetch_data(season):\n",
        "    teams_list = []\n",
        "    response = req.get(sofifa_url, headers=headers)\n",
        "    if response.status_code == req.codes.ok:\n",
        "        soup = BS(response.content, \"lxml\")\n",
        "        ul_list = soup.select(\"div.classement-table-body ul\")\n",
        "\n",
        "        for ul in ul_list:\n",
        "            li_list = ul.find_all(\"li\", class_=\"GeneralStats-row\")\n",
        "\n",
        "            for li in li_list:\n",
        "                team_data = []\n",
        "                try:\n",
        "                    position = li.find(\"div\", class_=\"GeneralStats-item--position\").text.strip()\n",
        "                    team = li.find(\"div\", class_=\"GeneralStats-item--club\").find(\"span\", class_=\"desktop-item\").text.strip()\n",
        "                    points = li.find(\"div\", class_=\"GeneralStats-item--points\").text.strip()\n",
        "                    stats = li.find_all(\"div\", class_=\"GeneralStats-item\")\n",
        "\n",
        "                    if len(stats) >= 11:  # Vérifier qu'il y a suffisamment d'éléments dans la liste\n",
        "                        played = stats[3].text.strip()\n",
        "                        won = stats[4].text.strip()\n",
        "                        drawn = stats[5].text.strip()\n",
        "                        lost = stats[6].text.strip()\n",
        "                        gf = stats[7].text.strip()\n",
        "                        ga = stats[8].text.strip()\n",
        "                    else:\n",
        "                        logging.error(f\"Not enough stats found for team: {team}\")\n",
        "                        continue\n",
        "\n",
        "                    team_data.extend([season, position, team, points, played, won, drawn, lost, gf, ga])\n",
        "                    teams_list.append(team_data)\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error parsing row: {e}\")\n",
        "                    continue\n",
        "    else:\n",
        "        logging.error(f\"Failed to retrieve data for season {season}\")\n",
        "    return teams_list\n",
        "\n",
        "# Monter Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Extraction des données pour toutes les saisons\n",
        "all_teams_list = []\n",
        "for season in ID_seasonId:\n",
        "    all_teams_list.extend(fetch_data(season))\n",
        "\n",
        "# Convertir la liste en DataFrame pandas\n",
        "df = pd.DataFrame(all_teams_list, columns=[\"Season\", \"Position\", \"Team\", \"Points\", \"Played\", \"Won\", \"Drawn\", \"Lost\", \"GF\", \"GA\"])\n",
        "\n",
        "# Convertir les colonnes en types numériques\n",
        "df['Points'] = pd.to_numeric(df['Points'], errors='coerce')\n",
        "df['Played'] = pd.to_numeric(df['Played'], errors='coerce')\n",
        "df['Won'] = pd.to_numeric(df['Won'], errors='coerce')\n",
        "df['Drawn'] = pd.to_numeric(df['Drawn'], errors='coerce')\n",
        "df['Lost'] = pd.to_numeric(df['Lost'], errors='coerce')\n",
        "df['GF'] = pd.to_numeric(df['GF'], errors='coerce')\n",
        "df['GA'] = pd.to_numeric(df['GA'], errors='coerce')\n",
        "\n",
        "# Enregistrer le dataframe dans Google Drive\n",
        "file_path = '/content/drive/My Drive/ligue1_data.csv'\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "print(f\"Données enregistrées dans Google Drive à l'emplacement: {file_path}\")"
      ]
    }
  ]
}